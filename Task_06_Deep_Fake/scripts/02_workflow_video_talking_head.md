# Video: talking-head or lip-sync

Choose one path:

## Path A — Talking head from a still image (SadTalker)
- Place a **royalty-free** or self-portrait image in `assets/portrait.jpg` (consented subject only).
- Generate audio first (see audio workflow).
- Run SadTalker per its README to produce `video/talking_head.mp4` from your audio + image.
- Add on-screen text `AI-Generated Interview` (CapCut/Resolve) in the first 3 seconds.

## Path B — Lip-sync an existing video (Wav2Lip)
- Record a short silent interview shot (you or a consenting actor) looking at the camera.
- Use Wav2Lip to sync your generated audio to the video.
- Export to `video/interview_synced.mp4`.

## Optional polishing
- Add lower-thirds text (names like "Coach Morgan Ellis") and a final frame linking to your GitHub repo.
- Keep total length **90–150 seconds**.

## Final checks
- Audible disclosure at start.
- On-screen label in first 3 seconds.
- File metadata embedded.
